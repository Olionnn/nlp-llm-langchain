{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting llama-index\n",
      "  Downloading llama_index-0.11.20-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: transformers in .\\venv\\lib\\site-packages (4.46.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in .\\venv\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in .\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: tqdm in .\\venv\\lib\\site-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in .\\venv\\lib\\site-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in .\\venv\\lib\\site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in .\\venv\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.20 (from llama-index)\n",
      "  Downloading llama_index_core-0.11.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in .\\venv\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: filelock in .\\venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in .\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in .\\venv\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in .\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in .\\venv\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in .\\venv\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in .\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in .\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: openai>=1.14.0 in .\\venv\\lib\\site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.52.2)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in .\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.20->llama-index) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in .\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.20->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in .\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.20->llama-index) (3.4.2)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in .\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.20->llama-index) (2.9.2)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt in .\\venv\\lib\\site-packages (from llama-index-core<0.12.0,>=0.11.20->llama-index) (1.16.0)\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.4-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n",
      "  Downloading llama_parse-0.5.12-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: click in .\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in .\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in .\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: jinja2 in .\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in .\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading yarl-1.17.0-cp311-cp311-win_amd64.whl.metadata (66 kB)\n",
      "     ---------------------------------------- 0.0/66.2 kB ? eta -:--:--\n",
      "     ----------------------- -------------- 41.0/66.2 kB 991.0 kB/s eta 0:00:01\n",
      "     ---------------------------------------- 66.2/66.2 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: anyio in .\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.20->llama-index) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.20->llama-index) (1.0.6)\n",
      "Requirement already satisfied: sniffio in .\\venv\\lib\\site-packages (from httpx->llama-index-core<0.12.0,>=0.11.20->llama-index) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.20->llama-index) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\venv\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.20->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in .\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.20->llama-index) (2.23.4)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.20->llama-index)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.6 MB 3.3 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.3/11.6 MB 3.4 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.4/11.6 MB 3.4 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/11.6 MB 3.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.8/11.6 MB 3.8 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/11.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.9/11.6 MB 4.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.2/11.6 MB 4.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.5/11.6 MB 4.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.1/11.6 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.5/11.6 MB 5.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.8/11.6 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.1/11.6 MB 5.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.4/11.6 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.6 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.3/11.6 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.7/11.6 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.0/11.6 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.3/11.6 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.6/11.6 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.9/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.2/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.5/11.6 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.8/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.2/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.5/11.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.6/11.6 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.8/11.6 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.9/11.6 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.1/11.6 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.3/11.6 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.5/11.6 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.6/11.6 MB 5.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.8/11.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.4/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.6/11.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.8/11.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.0/11.6 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.1/11.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.6/11.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
      "   ---------------------------------------- 0.0/255.8 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 184.3/255.8 kB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 255.8/255.8 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading llama_index-0.11.20-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.11.20-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.1/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.5/1.6 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.2/1.2 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.4/1.2 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.6/1.2 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.9/1.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.1/1.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 4.8 MB/s eta 0:00:00\n",
      "Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.8/15.8 MB 5.3 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.0/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.2/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.5/15.8 MB 5.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.8/15.8 MB 5.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.0/15.8 MB 5.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.3/15.8 MB 5.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.5/15.8 MB 5.3 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.8/15.8 MB 5.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/15.8 MB 5.4 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 3.3/15.8 MB 5.4 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.6/15.8 MB 5.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.9/15.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 4.1/15.8 MB 5.5 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.4/15.8 MB 5.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 4.7/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 5.0/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.3/15.8 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.6/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.9/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.1/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 5.6 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.7/15.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 7.0/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 7.3/15.8 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.9/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 8.2/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 8.6/15.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.9/15.8 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.5/15.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 9.8/15.8 MB 5.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 10.1/15.8 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.8 MB 6.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.8/15.8 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.9/15.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.2/15.8 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.3/15.8 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.5/15.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.6/15.8 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.8/15.8 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.0/15.8 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.1/15.8 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 12.2/15.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.4/15.8 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.5/15.8 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.6/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.8/15.8 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.9/15.8 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 13.0/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.2/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.3/15.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.6/15.8 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.8/15.8 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.1/15.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 4.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.6/15.8 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.7/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 14.9/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.0/15.8 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.4/15.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.6/15.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "   ---------------------------------------- 0.0/508.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/508.0 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 122.9/508.0 kB 7.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 143.4/508.0 kB 4.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 225.3/508.0 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 286.7/508.0 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 358.4/508.0 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 389.1/508.0 kB 1.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 419.8/508.0 kB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 450.6/508.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 471.0/508.0 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 508.0/508.0 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "   ---------------------------------------- 0.0/346.6 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/346.6 kB 660.6 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 61.4/346.6 kB 656.4 kB/s eta 0:00:01\n",
      "   ---------- ---------------------------- 92.2/346.6 kB 751.6 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 133.1/346.6 kB 714.4 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 174.1/346.6 kB 751.6 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 215.0/346.6 kB 772.8 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 256.0/346.6 kB 827.5 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 307.2/346.6 kB 827.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 346.6/346.6 kB 828.4 kB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB 991.0 kB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.1/11.0 MB 1.1 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.1/11.0 MB 1.1 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.2/11.0 MB 1.1 MB/s eta 0:00:11\n",
      "    --------------------------------------- 0.3/11.0 MB 1.1 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.3/11.0 MB 1.1 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/11.0 MB 1.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.5/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.6/11.0 MB 1.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.7/11.0 MB 1.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.7/11.0 MB 1.3 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.8/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.9/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.1/11.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 1.4 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.5/11.0 MB 1.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 1.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.9/11.0 MB 1.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.0/11.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 2.2/11.0 MB 1.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 2.3/11.0 MB 1.7 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.5/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 2.7/11.0 MB 1.8 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 1.9 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 1.9 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.9 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 1.9 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.3/11.0 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 3.5/11.0 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.6/11.0 MB 2.0 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/11.0 MB 2.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 3.9/11.0 MB 2.1 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 4.0/11.0 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.2/11.0 MB 2.1 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 4.3/11.0 MB 2.1 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.0/11.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.1/11.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.3/11.0 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.5/11.0 MB 2.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.7/11.0 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 5.8/11.0 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 6.0/11.0 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.7/11.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.9/11.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.0 MB 2.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 7.3/11.0 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.5/11.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 8.3/11.0 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.6/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.8/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.0/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.9/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.1/11.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.4/11.0 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 3.2 MB/s eta 0:00:00\n",
      "Using cached scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.6 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 143.4/381.6 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 327.7/381.6 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 381.6/381.6 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "   ---------------------------------------- 0.0/147.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 147.9/147.9 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading llama_cloud-0.1.4-py3-none-any.whl (176 kB)\n",
      "   ---------------------------------------- 0.0/176.8 kB ? eta -:--:--\n",
      "   ---------------------------------------  174.1/176.8 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 176.8/176.8 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading llama_parse-0.5.12-py3-none-any.whl (13 kB)\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "   ---------------------------------------- 0.0/295.8 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 194.6/295.8 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 295.8/295.8 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.1 MB 3.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.4/2.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.6/2.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/2.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.9/2.1 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.1 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.3/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.7/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 204.8/884.5 kB 6.1 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 419.8/884.5 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 634.9/884.5 kB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 829.4/884.5 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 884.5/884.5 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.6/51.6 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "   ---------------------------------------- 0.0/298.9 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 204.8/298.9 kB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 298.9/298.9 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.5/49.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading yarl-1.17.0-cp311-cp311-win_amd64.whl (89 kB)\n",
      "   ---------------------------------------- 0.0/89.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 89.9/89.9 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.9/44.9 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: striprtf, pytz, dirtyjson, tzdata, threadpoolctl, tenacity, soupsieve, pypdf, propcache, numpy, mypy-extensions, multidict, marshmallow, greenlet, frozenlist, deprecated, attrs, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, scipy, pandas, beautifulsoup4, aiosignal, scikit-learn, llama-cloud, dataclasses-json, aiohttp, llama-index-legacy, llama-index-core, sentence-transformers, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 beautifulsoup4-4.12.3 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 frozenlist-1.5.0 greenlet-3.1.1 llama-cloud-0.1.4 llama-index-0.11.20 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.20 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.16 llama-index-multi-modal-llms-openai-0.2.3 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.12 marshmallow-3.23.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 pandas-2.2.3 propcache-0.2.0 pypdf-4.3.1 pytz-2024.2 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.2.1 soupsieve-2.6 striprtf-0.0.26 tenacity-8.5.0 threadpoolctl-3.5.0 tiktoken-0.8.0 typing-inspect-0.9.0 tzdata-2024.2 yarl-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas sentence-transformers llama-index transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\project\\python\\thrainer\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Inisialisasi model Sentence Transformer buat embedding\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Assuming df is defined in a previous cell\n",
    "# Buat embedding untuk setiap deskripsi di CSV\n",
    "df['embedding'] = df['Description'].apply(lambda x: embedder.encode(x))\n",
    "\n",
    "# Simpan embedding untuk keperluan selanjutnya\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_description(question, df, embedder):\n",
    "    # Buat embedding dari pertanyaan\n",
    "    question_embedding = embedder.encode(question)\n",
    "    \n",
    "    # Hitung kesamaan (cosine similarity) antara pertanyaan dan deskripsi\n",
    "    similarities = df['embedding'].apply(\n",
    "        lambda x: np.dot(x, question_embedding) / \n",
    "                  (np.linalg.norm(x) * np.linalg.norm(question_embedding))\n",
    "    )\n",
    "    \n",
    "    # Ambil baris dengan similarity tertinggi\n",
    "    best_match = df.iloc[similarities.argmax()]\n",
    "    return best_match['Category'], best_match['Description']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "\n",
    "# Inisialisasi model Llama dan tokenizer\n",
    "model = LlamaForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"meta-llama/Llama-2-7b\")\n",
    "\n",
    "def ask_llama(question, category, description, model, tokenizer):\n",
    "    # Format prompt untuk model\n",
    "    prompt = f\"User asked: '{question}'.\\n\" \\\n",
    "             f\"Here is the relevant information:\\n\" \\\n",
    "             f\"Category: {category}\\nDescription: {description}\\n\" \\\n",
    "             \"Based on this information, provide a helpful answer.\"\n",
    "\n",
    "    # Tokenisasi dan generate jawaban\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=100)\n",
    "    \n",
    "    # Decode hasilnya\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pertanyaan dari user\n",
    "question = \"What services does your company provide?\"\n",
    "\n",
    "# Cari deskripsi yang relevan\n",
    "category, description = find_relevant_description(question, df, embedder)\n",
    "\n",
    "# Dapatkan jawaban dari Llama\n",
    "response = ask_llama(question, category, description, model, tokenizer)\n",
    "\n",
    "# Tampilkan jawaban\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
